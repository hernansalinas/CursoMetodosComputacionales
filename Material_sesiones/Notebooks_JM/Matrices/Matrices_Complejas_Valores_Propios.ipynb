{"cells":[{"cell_type":"code","execution_count":148,"metadata":{"cellView":"form","executionInfo":{"elapsed":316,"status":"ok","timestamp":1734019533737,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"},"user_tz":300},"id":"UuxNALCFhezT"},"outputs":[],"source":["#@title Librerias\n","\n","import numpy as np\n","import numpy.linalg as la\n","import scipy.linalg as sla\n","import matplotlib.pyplot as plt\n","import sympy as sp"]},{"cell_type":"markdown","source":["## Norma de una matriz\n","\n","En álgebra lineal y análisis numérico, la **norma de una matriz** es una medida que cuantifica el \"tamaño\" o \"magnitud\" de una matriz. Existen diferentes normas, cada una con aplicaciones específicas. Las más comunes son:\n","\n","### 1. **Norma Inducida por un Vector**\n","Sea $A \\in \\mathbb{R}^{m \\times n}$, y $\\|\\cdot\\|$ una norma vectorial. La norma inducida de $A$ está definida como:\n","\n","$$\n","\\|A\\| = \\sup_{x \\neq 0} \\frac{\\|Ax\\|}{\\|x\\|}\n","$$\n","\n","Esto mide cuánto puede amplificar $A$ un vector $x$ en términos de la norma del vector.\n","\n","#### Ejemplos:\n","- **Norma 1:**\n","  $$\\|A\\|_1 = \\max_{1 \\leq j \\leq n} \\sum_{i=1}^m |a_{ij}|$$\n","  Es el máximo de las sumas de los valores absolutos de las columnas de $A$.\n","\n","- **Norma Infinita:**\n","  $$\\|A\\|_\\infty = \\max_{1 \\leq i \\leq m} \\sum_{j=1}^n |a_{ij}|$$\n","  Es el máximo de las sumas de los valores absolutos de las filas de $A$.\n","\n","- **Norma Euclidiana (o 2-norma):**\n","  $$\\|A\\|_2 = \\sqrt{\\lambda_{\\text{máx}}(A^T A)}$$\n","  Donde $\\lambda_{\\text{máx}}$ es el valor propio máximo de $A^T A$.\n","\n","---\n","\n","### 2. **Norma de Frobenius**\n","Es una generalización de la norma euclidiana para matrices y se define como:\n","\n","$$\n","\\|A\\|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n |a_{ij}|^2}\n","$$\n","\n","Esto equivale a tomar la raíz cuadrada de la suma de los cuadrados de todos los elementos de $A$. Se relaciona con el trazo de $A^T A$:\n","\n","$$\n","\\|A\\|_F = \\sqrt{\\text{tr}(A^T A)}\n","$$\n","\n","---\n","\n","\n","La norma de una matriz depende de la elección del tipo de norma. Cada una tiene propiedades particulares útiles para diferentes contextos en álgebra lineal, como estabilidad numérica, análisis de convergencia, o medidas de error."],"metadata":{"id":"zxik_8fkaT0T"}},{"cell_type":"code","source":["A = np.array([[1, -2, 3],\n","              [4, 5, -6],\n","              [-7, 8, 9]])\n","\n","# Norma 1\n","norma_1 = np.max(np.sum(np.abs(A), axis=0))\n","\n","# Norma infinita\n","norma_inf = np.max(np.sum(np.abs(A), axis=1))\n","\n","# Norma de Frobenius\n","norma_frobenius = np.sqrt(np.sum(A**2))\n","\n","# Norma 2 (máximo valor singular)\n","norma_2 = np.linalg.norm(A, 2)\n","\n","print(\"Norma 1:\", norma_1)\n","print(\"Norma infinita:\", norma_inf)\n","print(\"Norma de Frobenius:\", norma_frobenius)\n","print(\"Norma 2:\", norma_2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NNxCyVDLaiO0","executionInfo":{"status":"ok","timestamp":1734019534299,"user_tz":300,"elapsed":57,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"886311ff-4052-4ed3-fd23-c83836e5bbc3"},"execution_count":149,"outputs":[{"output_type":"stream","name":"stdout","text":["Norma 1: 18\n","Norma infinita: 24\n","Norma de Frobenius: 16.881943016134134\n","Norma 2: 14.428023632158306\n"]}]},{"cell_type":"markdown","metadata":{"id":"Rzn_0QjRi1y5"},"source":["# Matrices Complejas: Transpuesta y Conjugada Transpuesta\n","\n","En álgebra lineal, una **matriz compleja** es una matriz cuyos elementos son números complejos, es decir, de la forma $a_{ij} = x + yi$, donde $x$ y $y$ son números reales e $i = \\sqrt{-1}$.\n","\n","A continuación, definimos los conceptos de transpuesta y conjugada transpuesta de una matriz compleja, con ejemplos prácticos.\n","\n","## Definición de una Matriz Compleja\n","Consideremos la matriz $A$ de tamaño $2 \\times 2$ como ejemplo:\n","\n","$$\n","A = \\begin{pmatrix}\n","1 + 2i & 3 - i \\\\\n","-2 + i & 4\n","\\end{pmatrix}.\n","$$\n","\n","## Transpuesta de una Matriz Compleja\n","La **transpuesta** de una matriz, denotada como $A^T$, se obtiene intercambiando las filas por las columnas. Es decir, el elemento en la posición $(i, j)$ de la matriz original pasa a la posición $(j, i)$ en la transpuesta.\n","\n","Para la matriz $A$, su transpuesta es:\n","\n","$$\n","A^T = \\begin{pmatrix}\n","1 + 2i & -2 + i \\\\\n","3 - i & 4\n","\\end{pmatrix}.\n","$$\n","\n","### Pasos para Calcular la Transpuesta:\n","1. Identificar los elementos $a_{ij}$ de la matriz original.\n","2. Intercambiar las posiciones $(i, j)$ por $(j, i)$.\n","3. Reorganizar los elementos en la nueva disposición.\n","\n","## Conjugada Transpuesta de una Matriz Compleja\n","La **conjugada transpuesta** de una matriz, también conocida como su **adjunta**, se denota como $A^*$ o $A^\\dagger$. Se calcula aplicando dos operaciones consecutivas:\n","1. **Conjugado complejo:** Cambiar el signo de la parte imaginaria de cada elemento de la matriz.\n","2. **Transposición:** Intercambiar filas y columnas.\n","\n","Para la matriz $A$, primero calculamos el conjugado complejo:\n","\n","$$\n","\\text{Conjugado complejo de } A =\n","\\begin{pmatrix}\n","1 - 2i & 3 + i \\\\\n","-2 - i & 4\n","\\end{pmatrix}.\n","$$\n","\n","Luego, transponemos el resultado para obtener la conjugada transpuesta:\n","\n","$$\n","A^* = \\begin{pmatrix}\n","1 - 2i & -2 - i \\\\\n","3 + i & 4\n","\\end{pmatrix}.\n","$$\n","\n","---\n","Finalmente, dada la matriz $A$:\n","\n","$$\n","A = \\begin{pmatrix}\n","1 + 2i & 3 - i \\\\\n","-2 + i & 4\n","\\end{pmatrix},\n","$$\n","\n","- Su **transpuesta** es:\n","\n","$$\n","A^T = \\begin{pmatrix}\n","1 + 2i & -2 + i \\\\\n","3 - i & 4\n","\\end{pmatrix}.\n","$$\n","\n","- Su **conjugada transpuesta** es:\n","\n","$$\n","A^\\dagger = \\begin{pmatrix}\n","1 - 2i & -2 - i \\\\\n","3 + i & 4\n","\\end{pmatrix}.\n","$$\n"]},{"cell_type":"code","execution_count":150,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":55,"status":"ok","timestamp":1734019534299,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"},"user_tz":300},"id":"bLAmxL6ShvKz","outputId":"8b51a067-e0db-4521-882d-8d634377c450"},"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz Original:\n","[[ 1.+2.j  3.-1.j]\n"," [-2.+1.j  4.+0.j]]\n","\n","Transpuesta:\n","[[ 1.+2.j -2.+1.j]\n"," [ 3.-1.j  4.+0.j]]\n","\n","Conjugada Transpuesta:\n","[[ 1.-2.j -2.-1.j]\n"," [ 3.+1.j  4.-0.j]]\n"]}],"source":["A = np.array([\n","    [1+2*1j, 3 - 1j],\n","    [-2+1j, 4]\n","], dtype=complex)\n","\n","transpuesta = A.T\n","conjugada = A.conjugate().T\n","\n","print(\"Matriz Original:\")\n","print(A)\n","print(\"\\nTranspuesta:\")\n","print(transpuesta)\n","print(\"\\nConjugada Transpuesta:\")\n","print(conjugada)"]},{"cell_type":"code","execution_count":150,"metadata":{"id":"Pt3VVdick0-_","executionInfo":{"status":"ok","timestamp":1734019534300,"user_tz":300,"elapsed":52,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}}},"outputs":[],"source":[]},{"cell_type":"markdown","source":["# Matrices Simétricas y Hermitianas\n","\n","Las matrices simétricas y hermitianas son tipos especiales de matrices cuadradas que presentan propiedades de simetría distintivas.\n","\n","## Matriz Simétrica\n","\n","### Propiedades\n","* **Definición**: Una matriz $A$ es simétrica si $A = A^T$\n","* Todos los elementos $a_{ij}$ son iguales a $a_{ji}$\n","* Válida solo para matrices de números reales\n","\n","### Estructura\n","* Simétrica respecto a la diagonal principal\n","* Los elementos por encima y debajo de la diagonal son idénticos\n","\n","$$\n","A = \\begin{pmatrix}\n","a & b & c \\\\\n","b & d & e \\\\\n","c & e & f \\\\\n","\\end{pmatrix}\n","$$\n","\n","## Matriz Hermitiana\n","\n","### Propiedades\n","* **Definición**: Una matriz $H$ es hermitiana si $H = H^\\dagger$\n","* Válida para matrices de números complejos\n","* Los elementos $h_{ij}$ son el conjugado complejo de $h_{ji}$\n","\n","### Características Específicas\n","* Elementos de la diagonal son números reales\n","* Elementos fuera de la diagonal son conjugados complejos entre sí\n","\n","$$\n","A = \\begin{pmatrix}\n","a & b + ci & d - ei \\\\\n","b - ci & f & g + hi \\\\\n","d + ei & g - hi & j \\\\\n","\\end{pmatrix}\n","$$\n","\n","## Diferencias Fundamentales\n","\n","| Característica | Matriz Simétrica | Matriz Hermitiana |\n","|---------------|------------------|-------------------|\n","| Tipo de Números | Reales | Complejos |\n","| Condición de Simetría | $A = A^T$ | $H = H^\\dagger$ |\n","| Elementos Diagonales | Cualquier número real | Solo números reales |\n","\n"],"metadata":{"id":"Gf-jvZVhh21u"}},{"cell_type":"code","source":["A = np.array([\n","    [1, 2, 3],\n","    [2, 4, 5],\n","    [3, 5, 6]\n","])\n","\n","trans = A.T\n","\n","np.array_equal(A, trans)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yFp_EdqsilBP","executionInfo":{"status":"ok","timestamp":1734019534300,"user_tz":300,"elapsed":51,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"45eeb5c5-3060-461d-ca0d-824a9047baef"},"execution_count":151,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":151}]},{"cell_type":"code","source":["# Paso 1: Crear una matriz cuadrada aleatoria\n","n = 3  # Tamaño de la matriz\n","A = np.random.randint(0, 10, (n, n))\n","\n","# Paso 2: Hacerla simétrica sumándola con su transpuesta y dividiendo por 2\n","A_simetrica = (A + A.T) / 2\n","\n","A_simetrica_2 = A@A.T\n","\n","# Mostrar la matriz original\n","print(\"Matriz original:\")\n","print(A)\n","# Mostrar la matriz simétrica\n","print(\"\\nMatriz simétrica:\")\n","print(A_simetrica)\n","\n","# Otra forma de matriz simétrica\n","print(\"\\nMatriz simétrica 2:\")\n","print(A_simetrica_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mHL8aD-skf1u","executionInfo":{"status":"ok","timestamp":1734019534300,"user_tz":300,"elapsed":47,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"46da10b5-2786-474c-be26-7ec1437a89cd"},"execution_count":152,"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz original:\n","[[0 7 6]\n"," [4 4 1]\n"," [9 9 1]]\n","\n","Matriz simétrica:\n","[[0.  5.5 7.5]\n"," [5.5 4.  5. ]\n"," [7.5 5.  1. ]]\n","\n","Matriz simétrica 2:\n","[[ 85  34  69]\n"," [ 34  33  73]\n"," [ 69  73 163]]\n"]}]},{"cell_type":"code","source":["H = np.array([\n","    [1, 2 + 3j, 4 - 1j],\n","    [2 - 3j, 5, 6 + 2j],\n","    [4 + 1j, 6 - 2j, 7]\n","])\n","\n","adj = H.conjugate().T\n","\n","np.array_equal(H, adj)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mswbVBWcjtA4","executionInfo":{"status":"ok","timestamp":1734019534301,"user_tz":300,"elapsed":44,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"aeba9c37-f6aa-48f5-fb99-21e09b6d7ff5"},"execution_count":153,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":153}]},{"cell_type":"code","source":["# Crear matriz compleja: parte real mas parte imaginaria\n","n = 3  # dimensión\n","H_re = np.random.randint(-10,10,size=(n,n)) # parte real\n","H_im = np.random.randint(-10,10,size=(n,n)) # parte imaginaria\n","H = H_re + 1j*H_im\n","\n","sim = H@H.conj().T\n","print(sim)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SUFgPFRSj5b8","executionInfo":{"status":"ok","timestamp":1734019534301,"user_tz":300,"elapsed":40,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"b251c30d-3974-433b-9aac-b1c84755b9d0"},"execution_count":154,"outputs":[{"output_type":"stream","name":"stdout","text":["[[299.  +0.j -51. -81.j  77. -55.j]\n"," [-51. +81.j 295.  +0.j -63.+282.j]\n"," [ 77. +55.j -63.-282.j 323.  +0.j]]\n"]}]},{"cell_type":"markdown","source":["### Importancia de Trabajar con Matrices Simétricas y Hermíticas\n","\n","#### Matrices Simétricas\n","Las matrices simétricas son fundamentales en muchas áreas de las matemáticas y la ciencia debido a sus propiedades únicas y aplicaciones prácticas. Algunas de las razones más importantes para trabajar con matrices simétricas incluyen:\n","\n","- **Propiedades Espectrales**: Las matrices simétricas tienen valores propios (eigenvalues) reales, lo cual es crucial en muchas aplicaciones físicas y de ingeniería.\n","- **Ortogonalidad**: Los vectores propios (eigenvectors) de matrices simétricas correspondientes a diferentes valores propios son ortogonales, lo que facilita los cálculos en algebra lineal y optimización.\n","- **Simplificación de Cálculos**: Las operaciones matemáticas y computacionales son más eficientes y estables cuando se trabaja con matrices simétricas debido a su estructura.\n","- **Aplicaciones en Física**: En mecánica cuántica y teoría de vibraciones, las matrices simétricas aparecen naturalmente en la descripción de sistemas físicos.\n","\n","#### Matrices Hermíticas\n","Las matrices hermíticas son igualmente importantes, especialmente en campos que involucran números complejos y aplicaciones cuánticas. Algunas razones clave para trabajar con matrices hermíticas son:\n","\n","- **Valores Propios Reales**: Al igual que las matrices simétricas, las matrices hermíticas tienen valores propios reales, lo que es vital para la estabilidad y realidad de las soluciones en problemas físicos.\n","- **Ortogonalidad Compleja**: Los vectores propios de matrices hermíticas correspondientes a diferentes valores propios son ortogonales con respecto al producto interior complejo, lo que facilita la análisis en espacios de Hilbert.\n","- **Teoría Cuántica**: En mecánica cuántica, los operadores hermíticos representan observables físicos, como la energía y el momento, asegurando que las mediciones sean reales.\n","- **Estabilidad Numérica**: Las matrices hermíticas poseen propiedades que garantizan la estabilidad numérica de algoritmos y métodos de solución en problemas de ingeniería y física.\n","\n","Trabajar con matrices simétricas y hermíticas no solo simplifica los cálculos matemáticos, sino que también asegura que los resultados sean físicamente significativos y estables.\n"],"metadata":{"id":"lxh0S2w8lwro"}},{"cell_type":"code","source":[],"metadata":{"id":"vhPLoyT1lxRc","executionInfo":{"status":"ok","timestamp":1734019534301,"user_tz":300,"elapsed":37,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}}},"execution_count":154,"outputs":[]},{"cell_type":"markdown","source":["### Matriz Ortogonal\n","Una **matriz ortogonal** es una matriz cuadrada real $Q$ que satisface la relación $Q^T Q = Q Q^T = I$, donde $Q^T$ es la transpuesta de $Q$ e $I$ es la matriz identidad. En otras palabras, las columnas (y filas) de una matriz ortogonal son vectores ortonormales, lo que significa que son mutuamente ortogonales y tienen norma unitaria.\n","\n","#### Propiedades de las Matrices Ortogonales:\n","- **Inversa**: La inversa de una matriz ortogonal es su transpuesta, es decir, $Q^{-1} = Q^T$.\n","- **Conservación de Longitudes**: Las transformaciones ortogonales conservan las longitudes de los vectores y los ángulos entre ellos.\n","- **Determinante**: El determinante de una matriz ortogonal es siempre $+1$ o $-1$.\n"],"metadata":{"id":"4Xa6o21FmtHh"}},{"cell_type":"code","source":["Q = np.array([\n","    [1/np.sqrt(2), 1/np.sqrt(2), 0],\n","    [-1/np.sqrt(2), 1/np.sqrt(2), 0],\n","    [0, 0, 1]\n","])\n","# Transpuesta\n","transpuesta = Q.T\n","# Inversa\n","inversa = np.linalg.inv(Q)\n","# Determinante\n","det = np.linalg.det(Q)\n","\n","print(\"Matriz Original:\")\n","print(Q)\n","print(\"\\nTranspuesta:\")\n","print(transpuesta)\n","print(\"\\nInversa:\")\n","print(inversa)\n","print(\"\\nDeterminante:\")\n","print(det)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3yc6cMvnm5FE","executionInfo":{"status":"ok","timestamp":1734019534302,"user_tz":300,"elapsed":37,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"d6c1afd2-fa46-4e59-f9eb-2ffa19d15f51"},"execution_count":155,"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz Original:\n","[[ 0.70710678  0.70710678  0.        ]\n"," [-0.70710678  0.70710678  0.        ]\n"," [ 0.          0.          1.        ]]\n","\n","Transpuesta:\n","[[ 0.70710678 -0.70710678  0.        ]\n"," [ 0.70710678  0.70710678  0.        ]\n"," [ 0.          0.          1.        ]]\n","\n","Inversa:\n","[[ 0.70710678 -0.70710678  0.        ]\n"," [ 0.70710678  0.70710678  0.        ]\n"," [ 0.          0.          1.        ]]\n","\n","Determinante:\n","0.9999999999999999\n"]}]},{"cell_type":"code","source":["# Comparación\n","print(np.isclose(transpuesta, inversa))\n","print(np.isclose(Q@Q.T, np.eye(len(Q))))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UnJKWBDqp7Qd","executionInfo":{"status":"ok","timestamp":1734019534302,"user_tz":300,"elapsed":34,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"56ed5ee2-aa4a-4eb5-effe-0525d42e2b99"},"execution_count":156,"outputs":[{"output_type":"stream","name":"stdout","text":["[[ True  True  True]\n"," [ True  True  True]\n"," [ True  True  True]]\n","[[ True  True  True]\n"," [ True  True  True]\n"," [ True  True  True]]\n"]}]},{"cell_type":"code","source":["# Usando linalg\n","sol = la.solve(Q, np.array([1,2,3]))\n","\n","# Usando las propiedades\n","otra_sol = Q.T@np.array([1,2,3])\n","\n","print(sol)\n","print(otra_sol)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5NOtdBwPpgUr","executionInfo":{"status":"ok","timestamp":1734019534302,"user_tz":300,"elapsed":30,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"c556c970-7933-4c34-a498-e2ed104ebc0f"},"execution_count":157,"outputs":[{"output_type":"stream","name":"stdout","text":["[-0.70710678  2.12132034  3.        ]\n","[-0.70710678  2.12132034  3.        ]\n"]}]},{"cell_type":"markdown","source":["### Matrices Unitarias\n","Las **matrices unitarias** son el análogo complejo de las matrices ortogonales. Una matriz cuadrada compleja $U$ es unitaria si satisface la relación $U^\\dagger U = U U^\\dagger = I$, donde $U^\\dagger$ es la transpuesta conjugada de $U$. En otras palabras, una matriz unitaria conserva las normas y los ángulos en espacios de números complejos.\n","\n","#### Propiedades de las Matrices Unitarias:\n","- **Inversa**: La inversa de una matriz unitaria es su transpuesta conjugada, es decir, $U^{-1} = U^\\dagger$.\n","- **Conservación de Longitudes**: Las transformaciones unitarias conservan las normas de los vectores y los ángulos entre ellos.\n","- **Determinante**: El determinante de una matriz unitaria tiene módulo $1$.\n","\n","\n"],"metadata":{"id":"j2KxE3NFoX5A"}},{"cell_type":"code","source":["U = np.array([\n","    [1/np.sqrt(2), 1j/np.sqrt(2)],\n","    [1j/np.sqrt(2), 1/np.sqrt(2)]\n","])\n","\n","transpuesta = U.conjugate().T\n","inversa = la.inv(U)\n","det = la.det(U)\n","\n","print(\"Matriz Original:\")\n","print(U)\n","print(\"\\nTranspuesta:\")\n","print(transpuesta)\n","print(\"\\nInversa:\")\n","print(inversa)\n","print(\"\\nDeterminante:\")\n","print(np.abs(det))\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vFDya_WfoYVb","executionInfo":{"status":"ok","timestamp":1734019534303,"user_tz":300,"elapsed":27,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"e126370a-8f23-430a-9b3e-6e58408ba29b"},"execution_count":158,"outputs":[{"output_type":"stream","name":"stdout","text":["Matriz Original:\n","[[0.70710678+0.j         0.        +0.70710678j]\n"," [0.        +0.70710678j 0.70710678+0.j        ]]\n","\n","Transpuesta:\n","[[0.70710678-0.j         0.        -0.70710678j]\n"," [0.        -0.70710678j 0.70710678-0.j        ]]\n","\n","Inversa:\n","[[0.70710678+0.j         0.        -0.70710678j]\n"," [0.        -0.70710678j 0.70710678+0.j        ]]\n","\n","Determinante:\n","0.9999999999999999\n"]}]},{"cell_type":"code","source":["np.isclose(transpuesta, inversa)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TzDAPztKrZnp","executionInfo":{"status":"ok","timestamp":1734019534303,"user_tz":300,"elapsed":24,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"25cf3ca5-0797-41bc-8084-9f9ecfd96395"},"execution_count":159,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ True,  True],\n","       [ True,  True]])"]},"metadata":{},"execution_count":159}]},{"cell_type":"code","source":["sol = la.solve(U, np.array([1,2]))\n","sol_2 = U.conjugate().T@np.array([1,2])\n","\n","print(sol)\n","print(sol_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RFCfiG0ysiYi","executionInfo":{"status":"ok","timestamp":1734019534303,"user_tz":300,"elapsed":20,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"ef97b477-a712-4874-d274-ed6f9c76629b"},"execution_count":160,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.70710678-1.41421356j 1.41421356-0.70710678j]\n","[0.70710678-1.41421356j 1.41421356-0.70710678j]\n"]}]},{"cell_type":"markdown","source":["### Relación entre Matrices Ortogonales y Unitarias:\n","- **Similitudes**: Ambas matrices conservan la longitud y los ángulos de los vectores, lo que las hace útiles en transformaciones geométricas y análisis de señales.\n","- **Diferencias**: Las matrices ortogonales operan en espacios reales, mientras que las matrices unitarias operan en espacios complejos.\n","- **Aplicaciones**: Las matrices ortogonales se utilizan en rotaciones y reflexiones en espacios euclidianos, mientras que las matrices unitarias son fundamentales en mecánica cuántica y procesamiento de señales.\n"],"metadata":{"id":"MOyzC_-7pdGp"}},{"cell_type":"code","source":[],"metadata":{"id":"gkSoJWJnpdZv","executionInfo":{"status":"ok","timestamp":1734019534303,"user_tz":300,"elapsed":16,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}}},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":["# Valores Propios de una Matriz\n","\n","Los valores propios (o eigenvalores) y los vectores propios (o eigenvectores) son conceptos fundamentales en álgebra lineal y tienen aplicaciones en diversas áreas como la física, la estadística y el análisis de sistemas.\n","\n","\n","Dada una matriz cuadrada $A$, un valor propio $\\lambda$ es un número tal que existe un vector no nulo $v$ (llamado vector propio) que satisface la siguiente ecuación:\n","\n","$$ A v = \\lambda v $$\n","\n","Esto significa que cuando la matriz $A$ actúa sobre el vector $v$, el resultado es el mismo vector $v$ multiplicado por el escalar $\\lambda$.\n","\n","## Cálculo de los Valores Propios\n","\n","Para encontrar los valores propios de una matriz $A$, se resuelve la siguiente ecuación característica:\n","\n","$$ \\text{det}(A - \\lambda I) = 0 $$\n","\n","donde:\n","- $\\text{det}$ denota el determinante de la matriz.\n","- $I$ es la matriz identidad del mismo tamaño que $A$.\n","- $\\lambda$ es un escalar.\n","\n","## Ejemplo\n","\n","Consideremos la matriz:\n","\n","\n","$$ A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} $$\n","\n","\n","Para encontrar los valores propios, resolvemos la ecuación característica:\n","\n","\n","\n","$$ \\text{det}(A - \\lambda I) = \\text{det}\\begin{pmatrix} 4 - \\lambda & 1 \\\\ 2 & 3 - \\lambda \\end{pmatrix} = 0 $$\n","\n","\n","\n","Esto se expande como:\n","\n","\n","\n","$$ (4 - \\lambda)(3 - \\lambda) - (1 \\cdot 2) = \\lambda^2 - 7\\lambda + 10 = 0 $$\n","\n","\n","\n","Resolviendo esta ecuación cuadrática, encontramos los valores propios:\n","\n","\n","\n","$$ \\lambda_1 = 5 $$\n","\n","\n","\n","\n","$$ \\lambda_2 = 2 $$\n","\n","\n","\n","Por lo tanto, los valores propios de la matriz $A$ son 5 y 2.\n"],"metadata":{"id":"FZS0Xp35t3NN"}},{"cell_type":"markdown","source":["# Vector Propio\n","\n","En álgebra lineal, un vector propio (o eigenvector) de una matriz $A$ es un vector no nulo que, al multiplicarlo por la matriz, se obtiene un escalar del mismo vector. Matemáticamente, un vector propio $v$ y un valor propio $\\lambda$ cumplen la siguiente ecuación:\n","\n","\n","\n","$$ A v = \\lambda v $$\n","\n","\n","\n","donde:\n","- $A$ es una matriz cuadrada.\n","- $v$ es un vector propio.\n","- $\\lambda$ es un valor propio asociado a $v$.\n","\n","## Ejemplo\n","\n","Consideremos la matriz:\n","\n","\n","\n","$$ A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} $$\n","\n","\n","\n","Para encontrar los valores propios de $A$, resolvemos la ecuación característica:\n","\n","\n","\n","$$ \\text{det}(A - \\lambda I) = 0 $$\n","\n","\n","\n","\n","\n","$$ \\begin{vmatrix} 4 - \\lambda & 1 \\\\ 2 & 3 - \\lambda \\end{vmatrix} = (4 - \\lambda)(3 - \\lambda) - 2 \\cdot 1 = \\lambda^2 - 7\\lambda + 10 - 2 = \\lambda^2 - 7\\lambda + 8 = 0 $$\n","\n","\n","\n","Resolviendo la ecuación cuadrática:\n","\n","\n","\n","$$ \\lambda^2 - 7\\lambda + 8 = 0 $$\n","\n","\n","\n","\n","\n","$$ \\lambda = \\frac{7 \\pm \\sqrt{49 - 32}}{2} = \\frac{7 \\pm 3}{2} $$\n","\n","\n","\n","\n","\n","$$ \\lambda_1 = 5, \\quad \\lambda_2 = 2 $$\n","\n","\n","\n","Ahora, para encontrar los vectores propios asociados a estos valores propios:\n","\n","1. Para $\\lambda_1 = 5$:\n","\n","\n","\n","$$ A v = 5 v $$\n","\n","\n","\n","\n","\n","$$ \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = 5 \\begin{pmatrix} x \\\\ y \\end{pmatrix} $$\n","\n","\n","\n","\n","\n","$$ \\begin{cases} 4x + y = 5x \\\\ 2x + 3y = 5y \\end{cases} $$\n","\n","\n","\n","Resolviendo este sistema, obtenemos $ y = x $. Por lo tanto, un vector propio correspondiente a $\\lambda_1 = 5$ es $ v_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $.\n","\n","2. Para $\\lambda_2 = 2$:\n","\n","\n","\n","$$ A v = 2 v $$\n","\n","\n","\n","\n","\n","$$ \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} \\begin{pmatrix} x \\\\ y \\end{pmatrix} = 2 \\begin{pmatrix} x \\\\ y \\end{pmatrix} $$\n","\n","\n","\n","\n","\n","$$ \\begin{cases} 4x + y = 2x \\\\ 2x + 3y = 2y \\end{cases} $$\n","\n","\n","\n","Resolviendo este sistema, obtenemos $ y = -2x $. Por lo tanto, un vector propio correspondiente a $\\lambda_2 = 2$ es $ v_2 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} $.\n","\n","## Resumen\n","\n","Para la matriz $ A = \\begin{pmatrix} 4 & 1 \\\\ 2 & 3 \\end{pmatrix} $, los valores propios son $\\lambda_1 = 5$ y $\\lambda_2 = 2$, con los correspondientes vectores propios:\n","\n","- Para $\\lambda_1 = 5$: $ v_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $\n","- Para $\\lambda_2 = 2$: $ v_2 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} $\n"],"metadata":{"id":"qg8sRIdY1qj7"}},{"cell_type":"code","source":["A = np.array([\n","    [4, 1],\n","    [2, 3]\n","])\n","\n","# Calcular los valores propios y vectores propios\n","valores_propios, vectores_propios = la.eig(A)\n","print(\"Valores propios:\", valores_propios)\n","print(\"Vectores propios:\\n\", vectores_propios)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n5lIt0np2WxV","executionInfo":{"status":"ok","timestamp":1734026561901,"user_tz":300,"elapsed":269,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"5e982a1e-f2a5-49fc-e927-7b98646be92b"},"execution_count":171,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores propios: [5. 2.]\n","Vectores propios:\n"," [[ 0.70710678 -0.4472136 ]\n"," [ 0.70710678  0.89442719]]\n"]}]},{"cell_type":"markdown","source":["# ¿Por qué los Vectores Propios son Diferentes?\n","\n","\n","La normalización es el proceso de escalar un vector de manera que tenga longitud 1. Si un vector propio manual se escala, mantiene la misma dirección pero cambia su magnitud. Por ejemplo:\n","\n","- El vector propio manual $\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$ puede normalizarse a $\\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\end{pmatrix} \\approx \\begin{pmatrix} 0.70710678 \\\\ 0.70710678 \\end{pmatrix}$.\n","- El vector propio manual $\\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$ puede normalizarse a $\\begin{pmatrix} \\frac{1}{\\sqrt{5}} \\\\ \\frac{-2}{\\sqrt{5}} \\end{pmatrix} \\approx \\begin{pmatrix} 0.4472136 \\\\ -0.89442719 \\end{pmatrix}$.\n","\n","\n","\n"],"metadata":{"id":"x4iFzxSg5FzQ"}},{"cell_type":"markdown","source":["# Método de Potencias\n","\n","El método de potencias es una técnica iterativa para encontrar el valor propio dominante (el de mayor magnitud) y su correspondiente vector propio de una matriz cuadrada $A$.\n","\n","## Pasos del Método de Potencias\n","\n","1. **Elección del Vector Inicial**:\n","   Escoge un vector inicial no nulo $x_0$. Este puede ser un vector aleatorio o una aproximación inicial del vector propio dominante.\n","\n","2. **Iteración**:\n","   Itera utilizando la siguiente fórmula:\n","   \n","   \n","\n","$$ x_{k+1} = \\frac{A x_k}{\\| A x_k \\|} $$\n","\n","\n","   \n","   donde $\\| A x_k \\|$ es la norma (longitud) del vector $A x_k$.\n","\n","3. **Convergencia**:\n","   Repite el paso anterior hasta que la secuencia de vectores $x_k$ converja. Esto ocurre cuando la dirección de $x_k$ deja de cambiar significativamente entre iteraciones.\n","\n","4. **Cálculo del Valor Propio Dominante**:\n","   Una vez que el vector $x_k$ haya convergido a un vector propio $v$, el valor propio dominante $\\lambda$ se puede aproximar utilizando:\n","   \n","   \n","\n","$$ \\lambda \\approx \\frac{(A v) \\cdot v}{v \\cdot v} $$\n","\n","\n","   \n","   donde $\\cdot$ denota el producto escalar.\n","\n","## Ejemplo\n","\n","Supongamos que queremos encontrar el valor propio dominante de la matriz:\n","\n","\n","\n","$$ A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} $$\n","\n","\n","\n","1. **Vector Inicial**:\n","   Escogemos un vector inicial, por ejemplo:\n","   \n","   \n","\n","$$ x_0 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} $$\n","\n","\n","\n","2. **Iteraciones**:\n","   Realizamos las iteraciones necesarias. Por simplicidad, mostramos solo la primera iteración:\n","\n","   \n","\n","$$ x_1 = A x_0 = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} $$\n","\n","\n","   \n","   Normalizamos $x_1$:\n","\n","   \n","\n","$$ x_1 = \\frac{1}{\\| Ax_0 \\|} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} = \\frac{1}{5} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} \\approx \\begin{pmatrix} 0.6 \\\\ 0.8 \\end{pmatrix} $$\n","\n","\n","\n","3. **Convergencia**:\n","   Continuamos iterando hasta que $x_k$ converge.\n","\n","4. **Valor Propio Dominante**:\n","   Finalmente, calculamos el valor propio dominante $\\lambda$ usando el vector propio $v$ obtenido.\n","\n"],"metadata":{"id":"J24MYvSzvk9J"}},{"cell_type":"code","source":["#@title Método de potencias\n","def metodo_potencias(A, max_iter=100, tolerancia=1e-10):\n","    \"\"\"\n","    Implementación del método de potencias para encontrar el valor propio dominante\n","    y su vector propio asociado.\n","\n","    Parámetros:\n","    A (numpy.ndarray): Matriz de entrada\n","    max_iter (int): Número máximo de iteraciones\n","    tolerancia (float): Criterio de convergencia\n","\n","    Retorna:\n","    tuple: (valor_propio, vector_propio)\n","    \"\"\"\n","    # Dimensión de la matriz\n","    n = A.shape[0]\n","\n","    # Vector inicial de unos\n","    x_k = np.ones(n)\n","\n","    for _ in range(max_iter):\n","        # Guardar el vector anterior para comparación\n","        x_k_anterior = x_k.copy()\n","\n","        # Multiplicar la matriz por el vector\n","        x_k = A @ x_k\n","\n","        # Normalizar el vector\n","        x_k = x_k / la.norm(x_k)\n","\n","        # Criterio de convergencia\n","        if la.norm(x_k - x_k_anterior) < tolerancia:\n","            break\n","\n","    # Calcular el valor propio dominante\n","    valor_propio = np.dot(x_k, A @ x_k) / np.dot(x_k, x_k)\n","\n","    return valor_propio, x_k"],"metadata":{"cellView":"form","id":"oXVGNnhTvlfx","executionInfo":{"status":"ok","timestamp":1734027080098,"user_tz":300,"elapsed":278,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}}},"execution_count":173,"outputs":[]},{"cell_type":"code","source":["A = np.array([\n","    [4, 1],\n","    [2, 3]\n","])\n","\n","valor_propio, vector_propio = metodo_potencias(A)\n","print(valor_propio)\n","print(vector_propio)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPv4csGawZki","executionInfo":{"status":"ok","timestamp":1734027126369,"user_tz":300,"elapsed":418,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"729ef248-4724-4be0-8db1-47f7ca0e2630"},"execution_count":174,"outputs":[{"output_type":"stream","name":"stdout","text":["5.0\n","[0.70710678 0.70710678]\n"]}]},{"cell_type":"code","source":["A@vector_propio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CiloRn5x0p5x","executionInfo":{"status":"ok","timestamp":1734027166330,"user_tz":300,"elapsed":245,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"867c3af1-d420-491a-d94c-b43433100106"},"execution_count":175,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.53553391, 3.53553391])"]},"metadata":{},"execution_count":175}]},{"cell_type":"code","source":["np.dot(valor_propio, vector_propio)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"obxTCtT00y_h","executionInfo":{"status":"ok","timestamp":1734027169981,"user_tz":300,"elapsed":250,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"28a677ff-25f8-4e47-b662-56d528b6cdfd"},"execution_count":176,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([3.53553391, 3.53553391])"]},"metadata":{},"execution_count":176}]},{"cell_type":"code","source":["np.isclose(la.det(A - valor_propio*np.eye(A.shape[0])),0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FQdRfNai1IUv","executionInfo":{"status":"ok","timestamp":1734019534738,"user_tz":300,"elapsed":40,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"4819abc9-1654-46cc-973a-71501da93f4b"},"execution_count":166,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":166}]},{"cell_type":"code","source":["np.isclose(la.norm(vector_propio), 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8ssOs5h1Mpj","executionInfo":{"status":"ok","timestamp":1734019534739,"user_tz":300,"elapsed":32,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"5892dd82-a599-4f1a-d812-71cce592280a"},"execution_count":167,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":167}]},{"cell_type":"markdown","source":["## Método QR para Valores y Vectores Propios\n","\n","El **método QR** es un procedimiento iterativo que permite calcular los valores y vectores propios de una matriz cuadrada $A$. Este método aprovecha las descomposiciones QR y la propiedad de que iterativamente $A_k$ converge hacia una matriz triangular superior, cuyos elementos diagonales son los valores propios de $A$.\n","\n","---\n","\n","### Descomposición QR\n","La descomposición QR de una matriz $A \\in \\mathbb{R}^{n \\times n}$ es una factorización de la forma:\n","\n","$$\n","A = Q R\n","$$\n","\n","Donde:\n","- $Q$ es una matriz ortogonal (o unitaria si es compleja), es decir, $Q^T Q = I$.\n","- $R$ es una matriz triangular superior.\n","\n","Esto puede calcularse mediante métodos como Gram-Schmidt, transformaciones de Householder, o rotaciones de Givens.\n","\n","---\n","\n","### Método Iterativo QR\n","El método QR para calcular los valores propios sigue estos pasos:\n","\n","1. **Inicialización**:\n","   Comenzar con $A_0 = A$, la matriz original.\n","\n","2. **Iteración**:\n","   Para $k = 0, 1, 2, \\dots$:\n","   - Realizar la descomposición $A_k = Q_k R_k$, donde $Q_k$ es ortogonal y $R_k$ es triangular superior.\n","   - Actualizar $A_{k+1} = R_k Q_k$.\n","\n","3. **Convergencia**:\n","   Repetir hasta que $A_k$ converja a una matriz triangular superior $T$, donde las entradas diagonales de $T$ son los valores propios de $A$.\n","\n","---\n","\n","\n","\n"],"metadata":{"id":"3dx0RvmbddDr"}},{"cell_type":"markdown","source":["## Ejemplo Numérico del Método QR\n","\n","Consideremos la matriz:\n","\n","$$\n","A = \\begin{bmatrix}\n","4 & 1 \\\\\n","2 & 3\n","\\end{bmatrix}\n","$$\n","\n","Aplicaremos el método QR paso a paso para encontrar los valores propios.\n","\n","---\n","\n","### Paso 1: Descomposición QR de $A$\n","Para realizar la descomposición QR de $A$, necesitamos obtener $Q$ (matriz ortogonal) y $R$ (matriz triangular superior). Utilizaremos el proceso de **Gram-Schmidt**.\n","\n","1. **Definimos las columnas de $A$ como vectores**:\n","   $$\n","   a_1 = \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix}, \\quad\n","   a_2 = \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix}.\n","   $$\n","\n","2. **Ortogonalizamos $a_2$ respecto a $a_1$**:\n","   - Normalizamos $a_1$ para obtener $q_1$:\n","    \n","$$ q_1 = \\frac{a_1}{\\|a_1\\|} = \\frac{\\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix}}{\\sqrt{4^2 + 2^2}} = \\frac{\\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix}}{\\sqrt{20}} = \\begin{bmatrix} \\frac{2}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} \\end{bmatrix}.\n","$$\n","\n","   - Proyección de $a_2$ sobre $q_1$:\n","$$\n","\\text{proy}_{q_1}(a_2) = (q_1^T a_2) q_1 = \\left(\\begin{bmatrix} \\frac{2}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} \\end{bmatrix}^T \\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix}\\right) \\begin{bmatrix} \\frac{2}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} \\end{bmatrix}.\n","$$\n","\n","     Calculando:\n","$$\n","q_1^T a_2 = \\frac{2}{\\sqrt{5}} \\cdot 1 + \\frac{1}{\\sqrt{5}} \\cdot 3 = \\frac{2 + 3}{\\sqrt{5}} = \\frac{5}{\\sqrt{5}} = \\sqrt{5}.\n","$$\n","\n","     Entonces:\n","$$\n","\\text{proy}_{q_1}(a_2) = \\sqrt{5} \\begin{bmatrix} \\frac{2}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} \\end{bmatrix} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}.\n","$$\n","\n","   - Calculamos $q_2$ como:\n","$$\n","q_2 = \\frac{a_2 - \\text{proy}_{q_1}(a_2)}{\\|a_2 - \\text{proy}_{q_1}(a_2)\\|} = \\frac{\\begin{bmatrix} 1 \\\\ 3 \\end{bmatrix} - \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}}{\\sqrt{(-1)^2 + 2^2}} = \\frac{\\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix}}{\\sqrt{5}} = \\begin{bmatrix} -\\frac{1}{\\sqrt{5}} \\\\ \\frac{2}{\\sqrt{5}} \\end{bmatrix}.\n","$$\n","\n","3. **Construimos $Q$ y $R$**:\n","   - $Q = \\begin{bmatrix} q_1 & q_2 \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{\\sqrt{5}} & -\\frac{1}{\\sqrt{5}} \\\\ \\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}} \\end{bmatrix}$.\n","   - Calculamos $R = Q^T A$:\n","$$\n","R = \\begin{bmatrix} \\frac{2}{\\sqrt{5}} & \\frac{1}{\\sqrt{5}} \\\\ -\\frac{1}{\\sqrt{5}} & \\frac{2}{\\sqrt{5}} \\end{bmatrix}^T \\begin{bmatrix} 4 & 1 \\\\ 2 & 3 \\end{bmatrix} = \\begin{bmatrix} \\sqrt{5} \\cdot 4 & \\sqrt{5} \\cdot 3 \\\\ 0 & \\sqrt{5} \\cdot 2 \\end{bmatrix}.\n","$$\n","\n","---\n","\n","### Paso 2: Primera Iteración\n","Actualizamos $A_1$ como:\n","\n","$$\n","A_1 = RQ.\n","$$\n","\n","Calculamos iterativamente hasta que $A_k$ converja a una matriz triangular superior. Los elementos diagonales de la matriz triangular son los **valores propios** de $A$. Por simplicidad, solo mostramos los resultados finales.\n","\n","---\n","\n","### Resultados\n","Después de varias iteraciones, obtenemos:\n","\n","$$\n","A_k \\approx \\begin{bmatrix} 5 & 1 \\\\ 0 & 2 \\end{bmatrix}.\n","$$\n","\n","Los **valores propios** de $A$ son $5$ y $2$."],"metadata":{"id":"RBrkVq_yeDK4"}},{"cell_type":"code","source":["#@title Método QR\n","def metodo_qr(A, tol=1e-10, max_iter=1000):\n","    n = A.shape[0]\n","    Ak = A.copy()\n","    for _ in range(max_iter):\n","        Q, R = la.qr(Ak)  # Descomposición QR\n","        Ak_next = R @ Q  # Actualización\n","        # Condición de parada: verificar convergencia diagonal\n","        if np.allclose(Ak, Ak_next, atol=tol):\n","            break\n","        Ak = Ak_next\n","\n","    # Los valores propios están en la diagonal de Ak\n","    valores_propios = np.diag(Ak)\n","    return valores_propios, Ak\n","\n","\n"],"metadata":{"id":"Mot_BzJp-YCx","executionInfo":{"status":"ok","timestamp":1734027484927,"user_tz":300,"elapsed":269,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"cellView":"form"},"execution_count":177,"outputs":[]},{"cell_type":"code","source":["A = np.array([[4, 1],\n","              [2, 3]])\n","\n","valores, matriz_triangular = metodo_qr(A)\n","print(\"Valores propios:\", valores)\n","print(\"Matriz triangular superior:\", matriz_triangular)"],"metadata":{"id":"0ie5CLxmd3tM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734027494042,"user_tz":300,"elapsed":340,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"41aac5f6-3ce5-41e7-acf2-bcf174c4345f"},"execution_count":179,"outputs":[{"output_type":"stream","name":"stdout","text":["Valores propios: [5. 2.]\n","Matriz triangular superior: [[5. 1.]\n"," [0. 2.]]\n"]}]},{"cell_type":"markdown","source":["### **Resumen de Métodos en NumPy para Resolver Matrices y Propiedades**\n","\n","NumPy es una biblioteca poderosa para operaciones matriciales en Python. A continuación, se presenta un resumen de métodos clave para resolver matrices, encontrar autovalores, autovectores y otras propiedades importantes.\n","\n","---\n","\n","### **1. Resolución de Sistemas de Ecuaciones Lineales**\n","\n","#### Sistema $Ax = b$\n","Para resolver sistemas de la forma $Ax = b$, se utiliza:\n","\n","```python\n","import numpy as np\n","\n","# Solución de sistemas lineales\n","x = np.linalg.solve(A, b)\n","```\n","\n","- **Propósito**: Calcula $x$ tal que $Ax = b$.\n","- **Requisito**: $A$ debe ser cuadrada y no singular.\n","\n","---\n","\n","### **2. Inversa y Determinante de una Matriz**\n","\n","#### Inversa:\n","```python\n","A_inv = np.linalg.inv(A)\n","```\n","- **Propósito**: Calcula $A^{-1}$.\n","- **Requisito**: $A$ debe ser cuadrada y no singular.\n","\n","#### Determinante:\n","```python\n","det_A = np.linalg.det(A)\n","```\n","- **Propósito**: Calcula $|A|$, el determinante.\n","- **Propiedades**: Si $|A| = 0$, la matriz es singular (no tiene inversa).\n","\n","---\n","\n","### **3. Autovalores y Autovectores**\n","\n","#### Cálculo de Autovalores y Autovectores:\n","Para calcular los autovalores $\\lambda$ y autovectores $v$ de una matriz $A$:\n","```python\n","valores, vectores = np.linalg.eig(A)\n","```\n","\n","- **Salida**:\n","  - `valores`: Autovalores $\\lambda_1, \\lambda_2, \\dots, \\lambda_n$.\n","  - `vectores`: Matriz donde cada columna es un autovector asociado.\n","\n","---\n","\n","### **4. Descomposición LU**\n","\n","La descomposición LU es útil para resolver sistemas lineales repetidamente.\n","\n","```python\n","from scipy.linalg import lu\n","\n","P, L, U = lu(A)\n","```\n","\n","- **Salida**:\n","  - `P`: Matriz de permutación.\n","  - `L`: Matriz triangular inferior.\n","  - `U`: Matriz triangular superior.\n","- **Propósito**: Factoriza $A$ como $A = P L U$.\n","\n","---\n","\n","### **5. Descomposición QR**\n","\n","Se utiliza para descomponer una matriz en una matriz ortogonal $Q$ y una triangular superior $R$.\n","\n","```python\n","Q, R = np.linalg.qr(A)\n","```\n","\n","- **Salida**:\n","  - `Q`: Matriz ortogonal.\n","  - `R`: Matriz triangular superior.\n","- **Propósito**: Factoriza $A$ como $A = QR$.\n","\n","---\n","\n","### **6. Descomposición SVD (Singular Value Decomposition)**\n","\n","Para una matriz $A$, la descomposición SVD proporciona:\n","$$\n","A = U \\Sigma V^T\n","$$\n","\n","```python\n","U, S, Vt = np.linalg.svd(A)\n","```\n","\n","- **Salida**:\n","  - `U`: Matriz unitaria.\n","  - `S`: Valores singulares (diagonal de $\\Sigma$).\n","  - `Vt`: Transpuesta de $V$.\n","- **Aplicaciones**: Reducción de dimensionalidad, pseudoinversas, etc.\n","\n","---\n","\n","### **7. Solución por Pseudoinversa**\n","\n","Para resolver sistemas sobredeterminados ($A$ no cuadrada):\n","```python\n","x = np.linalg.pinv(A) @ b\n","```\n","\n","- **Propósito**: Calcula una solución mínima cuadrática para $Ax = b$.\n","\n","---\n","\n","### **8. Normas y Propiedades de Matrices**\n","\n","#### Norma de una Matriz:\n","```python\n","norma = np.linalg.norm(A, ord=2)  # Norma 2 por defecto\n","```\n","\n","- **Propósito**: Calcula la norma de la matriz según la métrica especificada (`ord`).\n","\n","#### Rango de una Matriz:\n","```python\n","rango = np.linalg.matrix_rank(A)\n","```\n","\n","- **Propósito**: Calcula el rango de $A$.\n","\n","#### Traza:\n","```python\n","traza = np.trace(A)\n","```\n","\n","- **Propósito**: Suma de los elementos de la diagonal principal de $A$.\n","\n","---\n","\n","### **9. Exponencial, Logaritmo y Potencias de Matrices**\n","\n","#### Exponencial de una Matriz:\n","```python\n","from scipy.linalg import expm\n","\n","exponencial = expm(A)\n","```\n","\n","- **Propósito**: Calcula $e^A$, útil en sistemas dinámicos.\n","\n","#### Potencias Enteras:\n","```python\n","A_cuadrado = np.linalg.matrix_power(A, 2)\n","```\n","\n","- **Propósito**: Calcula $A^n$ para $n \\in \\mathbb{Z}$.\n","\n","---\n","\n","### **10. Verificación de Simetría y Positividad**\n","\n","#### Simetría:\n","```python\n","simetrica = np.allclose(A, A.T)\n","```\n","\n","- **Propósito**: Verifica si $A = A^T$.\n","\n","#### Positividad:\n","```python\n","positiva = np.all(np.linalg.eigvals(A) > 0)\n","```\n","\n","- **Propósito**: Verifica si $A$ es definida positiva.\n","\n","---\n","\n","### **Resumen Tabular**\n","\n","| **Función**                 | **Descripción**                   | **Código**                        |\n","|-----------------------------|-----------------------------------|-----------------------------------|\n","| Resolución de $Ax = b$      | Sistema lineal                   | `np.linalg.solve(A, b)`          |\n","| Inversa                    | Matriz inversa                   | `np.linalg.inv(A)`               |\n","| Determinante               | Determinante                     | `np.linalg.det(A)`               |\n","| Autovalores y Autovectores | $\\lambda, v$ de $A$              | `np.linalg.eig(A)`               |\n","| Descomposición LU          | $P, L, U$                        | `lu(A)`                          |\n","| Descomposición QR          | $Q, R$                           | `np.linalg.qr(A)`                |\n","| Descomposición SVD         | $U, \\Sigma, V^T$                 | `np.linalg.svd(A)`               |\n","| Norma de Matriz            | Norma $\\|A\\|$                    | `np.linalg.norm(A, ord=2)`       |\n","| Rango                      | Rango de $A$                     | `np.linalg.matrix_rank(A)`       |\n","| Traza                      | Suma diagonal principal          | `np.trace(A)`                    |\n","| Pseudoinversa              | Solución sobredeterminada        | `np.linalg.pinv(A)`              |\n","| Simetría                   | $A = A^T$                        | `np.allclose(A, A.T)`            |\n","| Positividad                | Definida positiva                | `np.all(np.linalg.eigvals(A) > 0)`|\n","\n"],"metadata":{"id":"ARm2uSxrgzLU"}},{"cell_type":"code","source":[],"metadata":{"id":"a6GXmqQRfaWy","executionInfo":{"status":"ok","timestamp":1734019534739,"user_tz":300,"elapsed":19,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}}},"execution_count":169,"outputs":[]},{"cell_type":"markdown","source":["# Matrices simbólicas y operaciones\n","\n","### **1. Configuración Inicial**\n","\n","Primero, debemos importar **SymPy** y definir las variables y matrices simbólicas:\n","\n","```python\n","import sympy as sp\n","\n","# Definir variables simbólicas\n","x, y, z = sp.symbols('x y z')  # Variables para ecuaciones\n","\n","# Definir una matriz simbólica\n","A = sp.Matrix([\n","    [1, 2, 3],\n","    [4, 5, 6],\n","    [7, 8, 9]\n","])\n","\n","# Definir un vector independiente\n","b = sp.Matrix([x, y, z])\n","```\n","\n","---\n","\n","### **2. Resolución de Sistemas de Ecuaciones Lineales**\n","\n","Para resolver un sistema $Ax = b$, utilizamos:\n","\n","```python\n","# Resolver Ax = b simbólicamente\n","x = sp.symbols('x1 x2 x3')  # Variables para la solución\n","X = sp.Matrix(x)  # Vector solución\n","sol = sp.linsolve((A, b))  # Resolver sistema\n","\n","print(sol)  # Muestra la solución simbólica\n","```\n","\n","- Si el sistema tiene solución única, devolverá la solución directa.\n","- Si es indeterminado o no tiene solución, devolverá las dependencias lineales o el vacío.\n","\n","---\n","\n","### **3. Inversa y Determinante**\n","\n","#### Calcular la inversa de una matriz simbólica:\n","```python\n","A_inv = A.inv()\n","print(A_inv)\n","```\n","\n","#### Calcular el determinante:\n","```python\n","det_A = A.det()\n","print(det_A)\n","```\n","\n","Si el determinante es cero, la matriz no tiene inversa.\n","\n","---\n","\n","### **4. Autovalores y Autovectores**\n","\n","#### Para calcular autovalores ($\\lambda$) y autovectores ($v$):\n","```python\n","# Autovalores\n","eigenvals = A.eigenvals()\n","print(eigenvals)\n","\n","# Autovectores\n","eigenvects = A.eigenvects()\n","print(eigenvects)\n","```\n","\n","- `eigenvals`: Devuelve un diccionario donde las claves son los autovalores y los valores, su multiplicidad.\n","- `eigenvects`: Devuelve una lista con tripletas: autovalor, multiplicidad, y los autovectores asociados.\n","\n","---\n","\n","### **5. Descomposición QR**\n","\n","Para obtener las matrices $Q$ y $R$ simbólicamente:\n","\n","```python\n","Q, R = A.QRdecomposition()\n","print(\"Q =\", Q)\n","print(\"R =\", R)\n","```\n","\n","---\n","\n","### **6. Descomposición LU**\n","\n","Para realizar la descomposición $A = L U$:\n","```python\n","L, U, perm = A.LUdecomposition()\n","print(\"L =\", L)\n","print(\"U =\", U)\n","```\n","\n","- `L`: Matriz triangular inferior.\n","- `U`: Matriz triangular superior.\n","- `perm`: Matriz de permutación simbólica (si es necesario).\n","\n","---\n","\n","\n"],"metadata":{"id":"47uAl5TkkUzl"}},{"cell_type":"code","source":["A = sp.Matrix([\n","    [2, -1, 0],\n","    [-1, 2, -1],\n","    [0, -1, 2]\n","])\n","b = sp.Matrix([1, 0, 1])\n","\n","# Resolver sistema Ax = b\n","X = sp.symbols('x1 x2 x3')\n","sol = sp.linsolve((A, b))\n","print(\"Solución del sistema Ax = b:\")\n","print(sol)\n","\n","# Calcular autovalores y autovectores\n","eigenvals = A.eigenvals()\n","eigenvects = A.eigenvects()\n","print(\"\\nAutovalores:\")\n","print(eigenvals)\n","print(\"\\nAutovectores:\")\n","print(eigenvects)\n","\n","# Descomposición QR\n","Q, R = A.QRdecomposition()\n","print(\"\\nDescomposición QR:\")\n","print(\"Q =\", Q)\n","print(\"R =\", R)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJcW0PSrkVtx","executionInfo":{"status":"ok","timestamp":1734019534740,"user_tz":300,"elapsed":19,"user":{"displayName":"JUAN MARCOS MARIN RAMIREZ","userId":"18118569551474732902"}},"outputId":"36db438b-ef9b-4866-d130-ba8768fab4fd"},"execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":["Solución del sistema Ax = b:\n","{(1, 1, 1)}\n","\n","Autovalores:\n","{2: 1, 2 - sqrt(2): 1, sqrt(2) + 2: 1}\n","\n","Autovectores:\n","[(2, 1, [Matrix([\n","[-1],\n","[ 0],\n","[ 1]])]), (2 - sqrt(2), 1, [Matrix([\n","[      1],\n","[sqrt(2)],\n","[      1]])]), (sqrt(2) + 2, 1, [Matrix([\n","[       1],\n","[-sqrt(2)],\n","[       1]])])]\n","\n","Descomposición QR:\n","Q = Matrix([[2*sqrt(5)/5, 3*sqrt(70)/70, sqrt(14)/14], [-sqrt(5)/5, 3*sqrt(70)/35, sqrt(14)/7], [0, -sqrt(70)/14, 3*sqrt(14)/14]])\n","R = Matrix([[sqrt(5), -4*sqrt(5)/5, sqrt(5)/5], [0, sqrt(70)/5, -8*sqrt(70)/35], [0, 0, 2*sqrt(14)/7]])\n"]}]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQEP9wR/wJVCu4rM7As8KQ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}